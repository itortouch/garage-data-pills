{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Algoritmos de Regresión"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**¿Qué es una regresión y para qué sirve?**   \n",
    "\n",
    "Es una herramienta estadística que nos permite entender cómo y en qué medida se relaciona una variable con otra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ejemplos reales:**   \n",
    "- Cálculo de gastos a final de mes\n",
    "- Predicción del consumo de electricidad del próximo día\n",
    "- Estimación del máximo ritmo cardíaco de una persona"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regresión lineal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### La regresión lineal en tu vida"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Todos utilizamos la regresión lineal simple en nuestro día a día.  \n",
    "\n",
    "**Por ejemplo**, vas al supermercado a comprar pollo que cuesta 5 €/Kg. Solo necesitas 400 gramos (0.4 Kg.) y quieres saber cuánto te va a costar. **¿Cómo lo calcularías?**\n",
    "\n",
    "![meme calculo](../data/img/math-meme.gif)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regla de tres**\n",
    "\n",
    "![regla de tres](../data/img/formula-regla-de-3-img1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$x = 5 * 0.4 / 1 = 2 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "5*0.4/1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ecuación de la recta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y = m * X + n $\n",
    "\n",
    "Siendo:   \n",
    "$ Y = variable 1 $  \n",
    "$ X = variable 2 $  \n",
    "$ m = pendiente $   \n",
    "$ n = ordenada $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Por ejemplo**   \n",
    "\n",
    "En verano, cuanto más calor hace más helados como. Digamos quiero predecir cuantos helados voy a comer un día de verano. Para ello he medido durante dos días la temperatura que hacía y cuantos helados me he comido:\n",
    "- Día 1: Hacía 30 grados y me he comido 3 helados\n",
    "- Día 2: Hacía 33 grados y me he comido 5 helados\n",
    "\n",
    "Con esta información y asumiendo que la relación entre las dos variables (temperatura y nº de helados que me he comido) es lineal, debería poder calcular cuántos helados voy a consimir al día siguiente mirando la temperatura del día siguiente. Pero primero, necesitamos averiguar cual es la ecuación de la recta de este caso:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siendo:   \n",
    "$ X_{1} = 30 $   $ Y_{1} = 3 $   \n",
    "$ X_{2} = 33 $   $ Y_{2} = 5 $\n",
    "\n",
    "Sustituimos en la ecuación de la recta:   \n",
    "$ 3 = m*30 + n => 3 - 30*m = n $   \n",
    "$ 5 = m*3 + n => 5 = m*33 + 3 - 30m => 2 = 3m => m=2/3 $   \n",
    "$ 3 - 30*m = n => n = 3 - 30*2/3 => n = -17 $\n",
    "\n",
    "La ecuación de la recta es:   \n",
    "$ Y = 2/3 * X - 17 $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pregunta\n",
    "He mirado el tiempo de mañana y dice que hará 42 grados. ¿Cuántos helados me comeré según lo anterior?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Solución"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ Y = 2/3 * 42 - 17 $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "2/3 * 42 - 17"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal simple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imagina que además de ti, tus amigos también han recoigdo datos de cuantos helados se han comido otros días. ¿Qué pasa entonces?\n",
    "\n",
    "Pongamos que los datos son los siguientes.\n",
    "\n",
    "Yo:\n",
    "- Día 1: Hacía 30 grados y me he comido 3 helados\n",
    "- Día 2: Hacía 33 grados y me he comido 5 helados\n",
    "\n",
    "Amigo 1:\n",
    "- Día 1: Hacía 29 grados y me he comido 1 helados\n",
    "- Día 2: Hacía 35 grados y me he comido 4 helados\n",
    "- \n",
    "Amigo 2:\n",
    "- Día 1: Hacía 32 grados y me he comido 6 helados\n",
    "- Día 2: Hacía 38 grados y me he comido 15 helados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pensad un momento, ¿cómo lo haríais?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si has llegado a la conclusión de que con la ecuación de la recta no podéis resolverlo, estás en lo correcto. Vamos a ver porqué es imposible que haya una recta que que se ajuste a estos 3 pares de datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos los datos en arrays\n",
    "temperaturas = np.array([30, 33, 29, 35, 32, 38])\n",
    "helados = np.array([3, 5, 1, 4, 6, 15])\n",
    "\n",
    "# Graficamos los datos en un scatter plot\n",
    "fig = px.scatter(x=temperaturas, y=helados, opacity=0.65)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mínimos cuadrados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cuando tenemos varios puntos para los que no existe una recta que los una a todos, pero aún así queremos obtener la recta que se queda más cerca de todos, necesitamos ajustarla lo mejor posible.\n",
    "\n",
    "De forma visual haríamos algo tal que así:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<details>\n",
    "  <summary>Click para abrir</summary>\n",
    "\n",
    "![OLS fit](../data/img/visual_OLS.gif)\n",
    "\n",
    "</details>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para resolver esto matemáticamente, existe un método llamado Mínimos Cuadrados (Ordinary Least Squares) el cual podemos ejecutar en la librería scikit-learn como Linear Regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el modelo de regresión lineal y lo \"ajustamos\" (fit) a nuestros datos\n",
    "model = LinearRegression()\n",
    "model.fit(temperaturas.reshape(-1, 1), helados)\n",
    "\n",
    "# Predecimos cuantos helados nos comeremos según la temperatura\n",
    "model.predict(np.array([36]).reshape(-1, 1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la recta del la regresión lineal que hemos entrenado\n",
    "x_range = np.linspace(temperaturas.min(), temperaturas.max(), 100)\n",
    "y_range = model.predict(x_range.reshape(-1, 1))\n",
    "\n",
    "fig = px.scatter(x=temperaturas, y=helados, opacity=0.65)\n",
    "fig.add_traces(go.Scatter(x=x_range, y=y_range, name='Mejor recta posible'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como veis en el gráfico, este ajuste (habitualmente fit en inglés) no es perfecto e introduce un error (también llamado residuo) en las predicciones de los datos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Errores en las regresiones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El error de una regresión indica como de bien o mal se ajusta la regresión a los datos reales. Sin errores, no tendríamos una forma matemática de evaluar los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helados_predichos = model.predict(temperaturas.reshape(-1, 1))\n",
    "error_simple = helados - helados_predichos\n",
    "print(error_simple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graficamos la recta del la regresión lineal que hemos entrenado prediciendo varios valores en el rango del gráfico\n",
    "x_range = np.linspace(temperaturas.min(), temperaturas.max(), 100)\n",
    "y_range = model.predict(x_range.reshape(-1, 1))\n",
    "\n",
    "fig = px.scatter(x=temperaturas, y=helados, opacity=0.65, error_y=[0,0,0,0,0,0], error_y_minus=error_simple)\n",
    "fig.add_traces(go.Scatter(x=x_range, y=y_range, name='Mejor recta posible'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_simple_medio = error_simple.mean()\n",
    "error_simple_medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "error_absoluto_medio = np.abs(error_simple).mean()\n",
    "error_absoluto_medio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, mean_absolute_percentage_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "helados - model.predict(temperaturas.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"mean_absolute_error:\\n{mean_absolute_error(helados, helados_predichos)}\\n\")\n",
    "print(f\"mean_squared_error:\\n{mean_squared_error(helados, helados_predichos)}\\n\")\n",
    "print(f\"mean_absolute_percentage_error:\\n{mean_absolute_percentage_error(helados, helados_predichos)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regresión lineal multiple\n",
    "Cuando el problema a resolver depende de más de una variable necesitamos generalizar la ecuación de la recta para poder predecir en base a distintas variables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$Y = m_{1} * X_{1} + m_{2} * X_{2} + m_{3} * X_{3}... + n $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Y\n",
    "print(helados)\n",
    "# X\n",
    "print(temperaturas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "peso = [78, 78, 65, 65, 90, 90]\n",
    "hizo_ejercicio = [0, 0, 0, 1, 0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = list(zip(temperaturas, peso, hizo_ejercicio))\n",
    "variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_lin_model = LinearRegression()\n",
    "multi_lin_model.fit(variables, helados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecimos cuantos helados nos comeremos según la temperatura\n",
    "multi_lin_model.predict([(36, 80, 1)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(helados, multi_lin_model.predict(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Arboles de decisión"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn import tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_model = DecisionTreeRegressor(random_state=42)\n",
    "# tree_model = DecisionTreeRegressor(random_state=42, max_depth=3)\n",
    "# tree_model = DecisionTreeRegressor(random_state=42, max_depth=3, max_leaf_nodes=2)\n",
    "tree_model = tree_model.fit(variables, helados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(tree_model, feature_names=[\"temperatura\", \"peso\", \"hizo_ejercicio\"], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(helados, tree_model.predict(variables))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelos \"Ensemble\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Un modelo \"ensemble\" es un método que combina las predicciones de múltiples modelos individuales para mejorar la robustez y precisión de las predicciones. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen distintos tipos de modelo ensemble en función de cómo se \"ensamblan\" esos modelos individuales. Los dos más importantes son:\n",
    "- Bagging (Bootstrap Aggregating)\n",
    "- Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bagging vs. Boosting](../data/img/bagging_boosting.jpeg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest\n",
    "1. Divide los datos en N conjusntos de datos aleatoriamente mezclados y pudiendo repetir muestras\n",
    "2. Ajusta un arbol de decisión a cada conjunto\n",
    "3. Promedia el resultado obtenido por cada arbol"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Random Forest](../data/img/random-forest_bootstrapping.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestRegressor(random_state=42, n_estimators=100)\n",
    "# random_forest_model = RandomForestRegressor(random_state=42, n_estimators=1, bootstrap=False)\n",
    "# random_forest_model = RandomForestRegressor(random_state=42, n_estimators=100, max_depth=3, max_leaf_nodes=2)\n",
    "random_forest_model = random_forest_model.fit(variables, helados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(helados, random_forest_model.predict(variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(random_forest_model.estimators_[0], feature_names=[\"temperatura\", \"peso\", \"hizo_ejercicio\"], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Boosting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradient Boosting\n",
    "1. Coge todo el dataset y ajusta un primer árbol de decisión\n",
    "2. Se calcula el target (Y) y también los errores (residuos)\n",
    "3. Ajusta un segundo arbol de decisión pero en lugar de ajustarlo al target (Y) lo ajustamos a los errores del anterior paso\n",
    "4. Se repite el paso 3 N veces\n",
    "5. De todos los arboles ajustados, del segundo al último arbol, se coge el error predicho, se multiplica por el leanring_rate y se suma a la predicción inicial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Bagging vs. Boosting](../data/img/gradient_boost.webp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gradient_boost_model = GradientBoostingRegressor(random_state=42, n_estimators=100, learning_rate=0.1)\n",
    "gradient_boost_model = GradientBoostingRegressor(random_state=42, n_estimators=1, subsample=1, criterion=\"squared_error\", learning_rate=1, max_depth=None)\n",
    "# gradient_boost_model = GradientBoostingRegressor(random_state=42, n_estimators=100, max_depth=3, max_leaf_nodes=2)\n",
    "gradient_boost_model = gradient_boost_model.fit(variables, helados)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_absolute_error(helados, gradient_boost_model.predict(variables))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(25,20))\n",
    "tree.plot_tree(gradient_boost_model.estimators_[0][0], feature_names=[\"temperatura\", \"peso\", \"hizo_ejercicio\"], filled=True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusión\n",
    "Resumen y comparación de los distintos modelos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Regresión lineal**\n",
    "- Ajuste muy rápido incluso en datasets grandes\n",
    "- Muy fácilmente interpretable\n",
    "- Dificil ajuste a distribuciones no lineales de datos\n",
    "- Poder predictivo muy limitado\n",
    "- Imposible overfitting (sobreajuste)\n",
    "\n",
    "**Bagging (Random Forest)**\n",
    "- Tiempo de ajuste crece con el volumen de datos y según los parámetros\n",
    "- Interpretable aunque muy tedioso cuando escala\n",
    "- Ajusta bien distribuciones no lineales de datos \n",
    "- Gran poder predictivo\n",
    "- Bastante resistente a overfiting\n",
    "\n",
    "**Boosting (Gradient Boost)**\n",
    "- El tiempo de ajuste crece con el volumen de datos y según los parámetros\n",
    "- Interpretable aunque muy tedioso cuando escala\n",
    "- Ajusta bien distribuciones no lineales de datos \n",
    "- Poder predictivo muy alto\n",
    "- Propenso a overfitting\n",
    "\n",
    "\n",
    "**Extra:**\n",
    "El Gradient Boosting ha sido una de las técnicas más populares de la última decada y se han desarrollado distintas implementaciones que mejoran la original en distintos aspectos:\n",
    "- Aceleración del ajuste con distintas técnicas\n",
    "- Mejora de poder de predicción\n",
    "- Mayor resistencia a overfitting\n",
    "  \n",
    "Actualmente estos modelos son los mejores a la hora de predecir datos tabulares. Algunos de estos son:\n",
    "- eXtreme Gradient Boosting (XGBoost)\n",
    "- LightGBM\n",
    "- CatBoost (Categorical Boosting)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garage_data_pills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
