{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cómo (no) predecir acciones en bolsa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen numerosas formas de arruinarte. De entre ellas, crear un algoritmo de machine learning que trate de predecir el valor de las acciones en bolsa para luego invertir tu dinero, es una de las más rápidas y efectivas.\n",
    "\n",
    "A continuación vamos a ver los distintos motivos por los que no suele ser una buena idea."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Modelos haciendo trampas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos a simular que somos una persona normal y corriente que está aprendiendo machine learning con Python y un buen día piensa \"oye, ya que estoy, por qué no intento predecir las acciones de la bolsa y así me saco un dinero extra\". Con la mejor de las intenciones, esta persona se pone manos a la obra.\n",
    "\n",
    "En primer lugar, lo que haríamos sería elegir una compañia que predecir. Una vez elegida, buscaríamos los datos diarios de cotización en un periodo de tiempo cualquiera. Pongamos entre 2015 y 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = datetime.datetime(2015, 1, 1)\n",
    "end = datetime.datetime(2021, 1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cogeremos Google para nuestro caso de estudio, pero te animo a que repliques todo el experimento con otras acciones\n",
    "simbolo_de_accion = \"GOOG\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_acciones = yf.download(simbolo_de_accion, start=start, end=end, progress=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_acciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para simplificar la tarea, intentaríamos quedarnos solo con el valor de cierre diario de la acción (Close). Este se convertirá en el valor a predecir, es decir, nuestro target (y)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_acciones = valor_acciones[[\"Close\"]].rename(columns={\"Close\": \"target\"})\n",
    "valor_acciones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez tenemos la información básica a predecir, el siguiente paso lógico sería buscar qué método de machine learning me permite hacer potentes predicciones de series temporales complejas. Por que claro, ya intuimos que los métodos tradicionales no nos vana a valer. Si no, todo el mundo estaría haciendo lo mismo y ganando mucho dinero, ¿verdad?\n",
    "\n",
    "Una rápida búsqueda en internet te lleva a las redes neuronales recurrentes, las cuáles son capaces de aprender teniendo en cuenta series de datos de forma recurrente (valga la redundancia). Concretamente nos encontramos con las Long Short-Term Memory (LSTM), un tipo de red que mejora las redes recurrentes tradicionales y es capaz de tener en cuenta tanto datos muy lejanos a los últimos registros como los más recientes.\n",
    "\n",
    "Suena genial, con las LSTM podremos simplemente tratar de predecir el valor de la acción a cierre de un día en base al valor del día anterior (X). Como estas redes tienen memoria a corto y a largo plazo, aprenderán los patrones de subida y bajada de valor.\n",
    "\n",
    "Vamos a ello."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El método shift de pandas desplaza todos los valores n veces (a este desplazamiento se le suele llamar lags)\n",
    "n_lags = 1\n",
    "valor_acciones[\"valor_cierre-1\"] = valor_acciones[\"target\"].shift(n_lags)\n",
    "valor_acciones = valor_acciones.dropna()\n",
    "valor_acciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Sequential\n",
    "from keras.layers import Dense, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definimos el modelo usando Keras sequential\n",
    "n_features = 1\n",
    "model = Sequential()\n",
    "model.add(LSTM(50, activation='relu', input_shape=(n_lags, n_features)))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mse')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dejamos un año fuera del entrenamiento para poder evaluar (vamos a excluir por ahora el año 2020)\n",
    "valor_acciones_train = valor_acciones.loc[:datetime.datetime(2019, 1, 1)]\n",
    "valor_acciones_test = valor_acciones.loc[datetime.datetime(2019, 1, 1):datetime.datetime(2020, 1, 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# El modelo LSTM espera los inputs en forma [samples, timesteps, features]\n",
    "X_train = valor_acciones_train[\"valor_cierre-1\"].to_numpy()\n",
    "X_train = X_train.reshape(X_train.shape[0], 1, 1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = valor_acciones_train[\"target\"].to_numpy()\n",
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "model.fit(X_train, y_train, epochs=200, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generamos test dataset\n",
    "X_test = valor_acciones_test[\"valor_cierre-1\"].to_numpy()\n",
    "X_test = X_test.reshape(X_test.shape[0], 1, 1)\n",
    "y_test = valor_acciones_test[\"target\"].to_numpy()\n",
    "\n",
    "# Generar predicciones\n",
    "y_pred_train = model.predict(X_train).flatten()  # Aplanar en caso de que sea necesario\n",
    "y_pred_test = model.predict(X_test).flatten()    # Aplanar en caso de que sea necesario\n",
    "\n",
    "# Preparar los datos para Plotly\n",
    "# Necesitarás las fechas o índices correspondientes a tus datos de entrenamiento y prueba\n",
    "indices_train = valor_acciones_train.index\n",
    "indices_test = valor_acciones_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_absolute_percentage_error\n",
    "\n",
    "# Calculando MAE y MAPE para el conjunto de entrenamiento\n",
    "mae_train = mean_absolute_error(y_train, y_pred_train)\n",
    "mape_train = mean_absolute_percentage_error(y_train, y_pred_train)\n",
    "\n",
    "# Calculando MAE y MAPE para el conjunto de prueba\n",
    "mae_test = mean_absolute_error(y_test, y_pred_test)\n",
    "mape_test = mean_absolute_percentage_error(y_test, y_pred_test)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f'Mean Absolute Error (Train): {round(mae_train,3)}')\n",
    "print(f'Mean Absolute Percentage Error (Train): {round(mape_train * 100, 3)}%')\n",
    "print(f'Mean Absolute Error (Test): {round(mae_test,3)}')\n",
    "print(f'Mean Absolute Percentage Error (Test): {round(mape_test * 100, 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son impresionantemente buenos. Vamos a graficarlos a ver qué aspecto tienen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear el gráfico con Plotly\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "fig = go.Figure()\n",
    "\n",
    "# Agregar las líneas de target y predicciones para entrenamiento\n",
    "fig.add_trace(go.Scatter(x=indices_train, y=y_train, mode='lines', name='Target Train', line=dict(color='darkturquoise')))\n",
    "fig.add_trace(go.Scatter(x=indices_train, y=y_pred_train, mode='lines', name='Predicción Train', line=dict(color='burlywood', dash='dot')))\n",
    "\n",
    "# Agregar las líneas de target y predicciones para prueba\n",
    "fig.add_trace(go.Scatter(x=indices_test, y=y_test, mode='lines', name='Target Test', line=dict(color='red')))\n",
    "fig.add_trace(go.Scatter(x=indices_test, y=y_pred_test, mode='lines', name='Predicción Test', line=dict(color='orange', dash='dot')))\n",
    "\n",
    "# Actualizar el layout para tener un título y etiquetas claras\n",
    "fig.update_layout(title='Comparación de Target vs. Predicciones',\n",
    "                  xaxis_title='Fecha',\n",
    "                  yaxis_title='Valor',\n",
    "                  legend_title='Leyenda')\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Veis algo raro? Tomaos tiempo para explorar el gráfico haciendo zoom e intentando entender qué pasa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**OVERFITTING**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculando MAE y MAPE para el conjunto de entrenamiento contra el valor del día anterior en lugar del correspondiente\n",
    "mae_train = mean_absolute_error(X_train.flatten(), y_pred_train)\n",
    "mape_train = mean_absolute_percentage_error(X_train.flatten(), y_pred_train)\n",
    "\n",
    "# Calculando MAE y MAPE para el conjunto de prueba contra el valor del día anterior en lugar del correspondiente\n",
    "mae_test = mean_absolute_error(X_test.flatten(), y_pred_test)\n",
    "mape_test = mean_absolute_percentage_error(X_test.flatten(), y_pred_test)\n",
    "\n",
    "# Imprimir los resultados\n",
    "print(f'Mean Absolute Error (Train -1 day): {round(mae_train,3)}')\n",
    "print(f'Mean Absolute Percentage Error (Train -1 day): {round(mape_train * 100, 3)}%')\n",
    "print(f'Mean Absolute Error (Test -1 day): {round(mae_test,3)}')\n",
    "print(f'Mean Absolute Percentage Error (Test -1 day): {round(mape_test * 100, 3)}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son prácticamente perfectos. Que los resultados de error con las features (X) sean menores que los de el target (y) es señal inequivoca de overfitting.\n",
    "\n",
    "Al fin y al cabo, predecir el valor de las acciones es muy complejo y cualquier sistema de optimización/aprendizaje tenderá a hacer esta \"trampa\" salvo que encuentre algún patrón mejor o forcemos que evite el overfitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posibles soluciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Existen muchas posibles soluciones a este problema que pueden usarse de forma independiente o combinadas. Aquí algunos ejemplos:\n",
    "- Transformar el target en una variable binaria (0 o 1) donde 0 significa que el valor es inferior al día anterior y 1 que el valor es mayor o igual al día anterior.\n",
    "- Añadir más lags (ventana más grande). e.g. La semana aterior, el mes anterior, tres meses atrás...\n",
    "- Utilizar modelos menos propensos al overfitting como el Random Forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. El ciclo económico te engaña"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "De acuerdo, hemos aprendido de los errores. Vamos a intentar mejorar el modelo aplicando todas las posibles soluciones al problema que hemos tenido previamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_acciones = valor_acciones.drop(columns=[\"valor_cierre-1\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_acciones.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valor_acciones[\"target_binario\"] = valor_acciones[\"target\"] > valor_acciones[\"target\"].shift(1)\n",
    "valor_acciones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generar_lags(df: pd.DataFrame, n_days_lags: list, target_column_name: str) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    for n in n_days_lags:\n",
    "        df[f'{target_column_name}-lag-{n}'] = df[target_column_name].shift(n)\n",
    "    return df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a generar las para la anterior semana completa, el mismo día dos semanas, 4 semanas y tres meses atrás.\n",
    "valor_acciones_lags = generar_lags(valor_acciones, [1, 2, 3, 4, 5, 6, 7, 7*2, 7*4, 7*4*3], \"target_binario\")\n",
    "valor_acciones_lags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dejamos el último año fuera del entrenamiento para poder evaluar (esta vez no excluimos 2020)\n",
    "valor_acciones_lags_train = valor_acciones_lags.loc[:datetime.datetime(2020, 1, 1)]\n",
    "valor_acciones_lags_test = valor_acciones_lags.loc[datetime.datetime(2020, 1, 1):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = valor_acciones_lags_train.loc[:, \"target_binario-lag-1\":\"target_binario-lag-84\"].to_numpy()\n",
    "y_train = valor_acciones_lags_train[\"target_binario\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_forest_model = RandomForestClassifier(random_state=42, n_estimators=100)\n",
    "random_forest_model = random_forest_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = valor_acciones_lags_test.loc[:, \"target_binario-lag-1\":\"target_binario-lag-84\"].to_numpy()\n",
    "y_test = valor_acciones_lags_test[\"target_binario\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_train = random_forest_model.predict(X_train)\n",
    "y_pred_test = random_forest_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Calculando el classification report para el conjunto de entrenamiento\n",
    "cr_train = classification_report(y_train, y_pred_train)\n",
    "\n",
    "# Calculando el classification report para el conjunto de prueba\n",
    "cr_test = classification_report(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(cr_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Por algún motivo, el error en el test es mucho más alto que en el train dataset. Veamos que aspecto tienen ambos periodos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indices_train = valor_acciones_lags_train.index\n",
    "indices_test = valor_acciones_lags_test.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "\n",
    "# Agregar las líneas de target y predicciones para entrenamiento\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=indices_train,\n",
    "        y=valor_acciones_lags_train[\"target\"],\n",
    "        mode=\"lines\",\n",
    "        name=\"Target Train\",\n",
    "        line=dict(color=\"darkturquoise\"),\n",
    "    )\n",
    ")\n",
    "\n",
    "# Agregar las líneas de target y predicciones para prueba\n",
    "fig.add_trace(\n",
    "    go.Scatter(\n",
    "        x=indices_test, y=valor_acciones_lags_test[\"target\"], mode=\"lines\", name=\"Target Test\", line=dict(color=\"red\")\n",
    "    )\n",
    ")\n",
    "\n",
    "# Actualizar el layout para tener un título y etiquetas claras\n",
    "fig.update_layout(\n",
    "    title=\"Explorar evolución del precio (target) por periodos\",\n",
    "    xaxis_title=\"Fecha\",\n",
    "    yaxis_title=\"Valor\",\n",
    "    legend_title=\"Leyenda\",\n",
    ")\n",
    "\n",
    "# Mostrar el gráfico\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parece que en 2020 hubo algunos movimientos extraños. Pero, más allá, de la baja precisión alcanzada en las predicciones, ¿cómo nos habría afectado económicamente estos errores?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## El problema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vamos a calcular cual es la variación media del target cuando este varia negativamente (False) en ambos periodos\n",
    "valor_acciones_lags_train[\"target-diff-1\"] = valor_acciones_lags_train[\"target\"].diff(1)\n",
    "valor_acciones_lags_test[\"target-diff-1\"] = valor_acciones_lags_test[\"target\"].diff(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variacion_media_negativa_train, variacion_media_positiva_train = (\n",
    "    valor_acciones_lags_train.query(\"target_binario == False\")[\"target-diff-1\"].mean(),\n",
    "    valor_acciones_lags_train.query(\"target_binario == True\")[\"target-diff-1\"].mean(),\n",
    ")\n",
    "print(\n",
    "    f\"La variación media negativa en train dataset es de {round(variacion_media_negativa_train,3)} y la positiva es de {round(variacion_media_positiva_train,3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variacion_media_negativa_test, variacion_media_positiva_test = (\n",
    "    valor_acciones_lags_test.query(\"target_binario == False\")[\"target-diff-1\"].mean(),\n",
    "    valor_acciones_lags_test.query(\"target_binario == True\")[\"target-diff-1\"].mean(),\n",
    ")\n",
    "print(\n",
    "    f\"La variación media negativa en test dataset es de {round(variacion_media_negativa_test,3)} y la positiva es de {round(variacion_media_positiva_test,3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variacion_media_negativa_train_fallo, variacion_media_positiva_train_fallo = (\n",
    "    valor_acciones_lags_train[valor_acciones_lags_train[\"target_binario\"] != y_pred_train]\n",
    "    .query(\"target_binario == False\")[\"target-diff-1\"]\n",
    "    .mean(),\n",
    "    valor_acciones_lags_train.query(\"target_binario == True\")[\"target-diff-1\"].mean(),\n",
    ")\n",
    "print(\n",
    "    f\"La variación media negativa en train dataset para aquellos casos en los que el modelo falla es de {round(variacion_media_negativa_train_fallo,3)} y la positiva es de {round(variacion_media_positiva_train_fallo,3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variacion_media_negativa_test_fallo, variacion_media_positiva_test_fallo = (\n",
    "    valor_acciones_lags_test[valor_acciones_lags_test[\"target_binario\"] != y_pred_test]\n",
    "    .query(\"target_binario == False\")[\"target-diff-1\"]\n",
    "    .mean(),\n",
    "    valor_acciones_lags_test.query(\"target_binario == True\")[\"target-diff-1\"].mean(),\n",
    ")\n",
    "print(\n",
    "    f\"La variación media negativa en test dataset para aquellos casos en los que el modelo falla es de {round(variacion_media_negativa_test_fallo,3)} y la positiva es de {round(variacion_media_positiva_test_fallo,3)}\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como podemos observar, el problema aquí está en que la tendencia de las acciones habitualmente va acompasado con el ciclo económico. Por su lado, en el ciclo ecónomico inervienen una cantidad enorme de factores y fenomenos que pueden cambiar en periodos de tiempo muy pequeño. Algunos de los fenómenos que han cambiado radicalmente el ciclo económico fueron:\n",
    "- La crisis inmobiliaria de 2008\n",
    "- La crisis del COVID en 2020\n",
    "\n",
    "Para más inri, dependiendo del tipo de compañía analizada, pueden haber fenómenos específicos de su sector como la burbuja de las .com en los 2000.\n",
    "\n",
    "En otas ocasiones, los cambios de ciclo o tendencia de una acción pueden ser tan aleatorios como los vividos recientemente con el fenomeno WallStreetBets y GameStop.\n",
    "\n",
    "Aquí entra la famosa frase de consejo financiero:\n",
    "\n",
    "`rendimientos pasados no garantizan rendimientos futuros`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Posibles soluciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Siendo honesto, este tipo de problemas es genuinamente compejo dada la gran cantidad de variables y fenomenos que, juntos, hacen de este problema uno con casi infinitos grados de libertad. Cuesta imaginar como podríamos estructurar la recolección de datos continua y fiable que nos hubiera permitido anticipar las caidas de las bolsas en marzo de 2020. Sin embargo, si que se pueden desarrollar sistemas que mitiguen o minimicen las perdidas y permitan estrategias que en global ganen dinero. Os animo a que invesigues este camino con mucha prudencia y sin prisa, es un trabajo realmente arduo, si es que es posible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bonus. Intentar entrenar un modelo capaz de predecir distintas acciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En algun momento de este video quizá hayas podido pensar que la solución a algunos problemas sea entrenar el modelo con muchos datos de distintas acciones, distintos periodos temporales y áreas geográficas. Intuitivamente, cuanto mayor y más variada es la muestra, mejor puede llegar a ser el modelo entrenado para generalizar casos. \n",
    "\n",
    "Esto tiene sentido. Pero la cantidad de información y distintas features que habría que conseguir para poder construir un modelo que puediera generalizar de esa forma, sería realmente enorme, hablamos de miles de features. \n",
    "\n",
    "Aún en el supuesto de que pudieramos conseguir ese titánico esfuerzo, todavía tendríamos que lidiar con un problema si cabe más complejo que es la maldición de la dimensionalidad. Sin querer entrar en detalles, la maldición de la dimensionalidad se refiere a cuando el train dataset contiene tantas features (dimensiones) que la densidad de datos (muestras) en el espacio generado por el modelo estará practicamente vacío y le costará muchísimo realizar predicciones robustas. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La predicción de acciones (stocks) es un problema apasionante, que a muchos nos reta y motiva durante nuestros primeros pasos en la ciencia de datos. Mientras esto no nos obsesione ni nos afecte personalmente en lo económico, es un problema perfecto para progresar poco a poco y comprender multitud de conceptos como:\n",
    "- Análisis de series temporales\n",
    "- Procesamiento y transformación de datos\n",
    "- Sistemas/problemas complejos con alta dimensionalidad\n",
    "- Modelización (deep learning + machine learning)\n",
    "\n",
    "Dicho esto, espero que aunque sigas sin saber cómo predecir el valor de las acciones, al menos sepas como NO hacerlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "garage_data_pills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
